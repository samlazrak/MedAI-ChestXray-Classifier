{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Chest X-ray Images (Apple Silicon Optimized)\n",
    "\n",
    "This notebook supports both TensorFlow/Keras and PyTorch training. Set the `PYTORCH_TRAINING` flag to choose the backend.\n",
    "\n",
    "- Dataset: ChestX-ray14 (CXR8)\n",
    "- Binary classification: Normal vs Abnormal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Flags ---\n",
    "PYTORCH_TRAINING = True  # Set to True to use PyTorch instead of Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "import warnings\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Exploration ---\n",
    "data_path = '../datasets/CXR8/'\n",
    "labels_df = pd.read_csv(os.path.join(data_path, 'Data_Entry_2017_v2020.csv'))\n",
    "labels_df['binary_label'] = (labels_df['Finding Labels'] != 'No Finding').astype(int)\n",
    "\n",
    "# Create a balanced dataset\n",
    "normal_samples = labels_df[labels_df['binary_label'] == 0]\n",
    "abnormal_samples = labels_df[labels_df['binary_label'] == 1]\n",
    "min_samples = min(len(normal_samples), len(abnormal_samples))\n",
    "balanced_normal = normal_samples.sample(n=min_samples, random_state=42)\n",
    "balanced_abnormal = abnormal_samples.sample(n=min_samples, random_state=42)\n",
    "balanced_df = pd.concat([balanced_normal, balanced_abnormal]).reset_index(drop=True)\n",
    "\n",
    "# Split the data\n",
    "train_df, temp_df = train_test_split(balanced_df, test_size=0.3, random_state=42, stratify=balanced_df['binary_label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['binary_label'])\n",
    "\n",
    "image_dir = os.path.join(data_path, 'images/extracted_images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- PyTorch Training ---\n",
    "\n",
    "This block runs if `PYTORCH_TRAINING = True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training:   0%|          | 0/2265 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training:   5%|â–         | 103/2265 [01:36<33:07,  1.09it/s]"
     ]
    }
   ],
   "source": [
    "if PYTORCH_TRAINING:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torchvision import transforms\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    class CXRDataset(Dataset):\n",
    "        def __init__(self, df, img_dir, transform=None):\n",
    "            self.df = df.reset_index(drop=True)\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "        def __getitem__(self, idx):\n",
    "            img_name = self.df.loc[idx, 'Image Index']\n",
    "            label = self.df.loc[idx, 'binary_label']\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            image = Image.open(img_path).convert('L')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    train_dataset = CXRDataset(train_df, image_dir, transform)\n",
    "    val_dataset = CXRDataset(val_df, image_dir, transform)\n",
    "    test_dataset = CXRDataset(test_df, image_dir, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    class SimpleCNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SimpleCNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "            self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "            self.fc1 = nn.Linear(64 * 28 * 28, 64)\n",
    "            self.dropout1 = nn.Dropout(0.5)\n",
    "            self.dropout2 = nn.Dropout(0.3)\n",
    "            self.fc2 = nn.Linear(64, 1)\n",
    "        def forward(self, x):\n",
    "            x = self.pool(torch.relu(self.conv1(x)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            x = self.pool(torch.relu(self.conv3(x)))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.dropout1(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = torch.sigmoid(self.fc2(x))\n",
    "            return x.squeeze(1)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimpleCNN().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} - Training'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} - Validation'):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print('Saved best model to best_model.pth')\n",
    "    print('PyTorch training complete.')\n",
    "\n",
    "    # Test evaluation (optional)\n",
    "    model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    print(f'Test Accuracy: {correct/total:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
